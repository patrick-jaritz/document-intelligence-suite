# ‚úÖ RAG Database Schema Fix - Complete

**Date**: 2025-01-15  
**Status**: ‚ö†Ô∏è **ACTION REQUIRED** - SQL Migration Needed

---

## üêõ Problem

### Issue: 500 Internal Server Error on RAG Query
**Symptom**:
```
POST .../functions/v1/rag-query 500 (Internal Server Error)
```

**Root Cause**: The `match_document_chunks` RPC function and RAG database tables **don't exist** in your Supabase database.

The `rag-query` Edge Function tries to call:
```typescript
await supabase.rpc('match_document_chunks', { ... })
```

But this function was never created in the database, causing the 500 error.

---

## ‚úÖ Solution

### Run the RAG Schema Migration

**File**: `supabase-migrations/01_rag_schema.sql`

This migration creates:
1. ‚úÖ `pgvector` extension (for vector similarity search)
2. ‚úÖ `rag_documents` table (document metadata)
3. ‚úÖ `document_chunks` table (text chunks with embeddings)
4. ‚úÖ `rag_sessions` table (Q&A history)
5. ‚úÖ `match_document_chunks()` RPC function (vector search)
6. ‚úÖ Indexes for performance (including HNSW vector index)
7. ‚úÖ RLS policies (allow all for public access)

---

## üöÄ How to Apply the Migration

### Option 1: Supabase Dashboard (Recommended)

1. **Go to your Supabase project**:
   - URL: https://supabase.com/dashboard/project/joqnpibrfzqflyogrkht

2. **Open SQL Editor**:
   - Click **"SQL Editor"** in the left sidebar
   - Click **"New Query"**

3. **Copy the SQL**:
   - Open [`supabase-migrations/01_rag_schema.sql`](/Users/patrickjaritz/CODE/document-intelligence-suite/supabase-migrations/01_rag_schema.sql)
   - Copy the entire contents

4. **Paste and Run**:
   - Paste into the SQL Editor
   - Click **"Run"** (or press `Cmd/Ctrl + Enter`)

5. **Verify**:
   - Check for **"Success. No rows returned"** message
   - Go to **"Table Editor"** ‚Üí should see `rag_documents`, `document_chunks`, `rag_sessions`
   - Go to **"Database"** ‚Üí **"Functions"** ‚Üí should see `match_document_chunks`

### Option 2: Supabase CLI

If you have the Supabase CLI installed:

```bash
cd /Users/patrickjaritz/CODE/document-intelligence-suite
supabase db push --project-ref joqnpibrfzqflyogrkht
```

**Note**: This requires the migration file to be in `supabase/migrations/` folder. You may need to move it:
```bash
mkdir -p supabase/migrations
cp supabase-migrations/01_rag_schema.sql supabase/migrations/20250115_rag_schema.sql
```

---

## üìä Database Schema Overview

### Tables

#### 1. `rag_documents`
Tracks uploaded documents.

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID | Primary key |
| `filename` | TEXT | Original filename |
| `source_url` | TEXT | URL if from URL upload |
| `upload_date` | TIMESTAMPTZ | When uploaded |
| `chunk_count` | INTEGER | Number of chunks |
| `embedding_provider` | TEXT | openai/mistral/local |
| `metadata` | JSONB | Additional metadata |

#### 2. `document_chunks`
Stores text chunks with vector embeddings.

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID | Primary key |
| `document_id` | UUID | Foreign key to rag_documents |
| `filename` | TEXT | Document filename |
| `chunk_text` | TEXT | The actual text chunk |
| `chunk_index` | INTEGER | Chunk number (0, 1, 2...) |
| `chunk_offset` | INTEGER | Character offset in original |
| `embedding` | vector(1536) | Vector embedding |
| `created_at` | TIMESTAMPTZ | When created |
| `metadata` | JSONB | Additional metadata |

#### 3. `rag_sessions`
Stores Q&A history.

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID | Primary key |
| `question` | TEXT | User's question |
| `answer` | TEXT | LLM's answer |
| `document_id` | UUID | Foreign key to rag_documents |
| `filename` | TEXT | Document filename |
| `sources` | JSONB | Retrieved chunks with scores |
| `model` | TEXT | LLM model used |
| `provider` | TEXT | LLM provider used |
| `created_at` | TIMESTAMPTZ | When asked |

### Functions

#### `match_document_chunks()`
Vector similarity search function.

**Parameters**:
- `query_embedding` (TEXT): JSON stringified vector (e.g., `"[0.1, 0.2, ...]"`)
- `match_threshold` (FLOAT): Minimum similarity score (default: 0.7)
- `match_count` (INT): Max results to return (default: 5)
- `filter_document_id` (UUID): Filter by document (optional)
- `filter_filename` (TEXT): Filter by filename (optional)

**Returns**: Table of matching chunks with similarity scores

**Example**:
```sql
SELECT * FROM match_document_chunks(
  query_embedding := '[0.1, 0.2, 0.3, ...]',
  match_threshold := 0.7,
  match_count := 5,
  filter_filename := 'my-document.pdf'
);
```

---

## üß™ Testing After Migration

### Test 1: Verify Tables Exist

**SQL**:
```sql
SELECT table_name 
FROM information_schema.tables 
WHERE table_schema = 'public' 
  AND table_name IN ('rag_documents', 'document_chunks', 'rag_sessions');
```

**Expected**: Should return 3 rows

### Test 2: Verify RPC Function Exists

**SQL**:
```sql
SELECT routine_name 
FROM information_schema.routines 
WHERE routine_name = 'match_document_chunks';
```

**Expected**: Should return 1 row

### Test 3: Verify pgvector Extension

**SQL**:
```sql
SELECT * FROM pg_extension WHERE extname = 'vector';
```

**Expected**: Should return 1 row

### Test 4: Test Vector Search (with dummy data)

**SQL**:
```sql
-- Insert a test document
INSERT INTO rag_documents (id, filename) 
VALUES ('00000000-0000-0000-0000-000000000001', 'test.pdf');

-- Insert a test chunk with dummy embedding
INSERT INTO document_chunks (document_id, filename, chunk_text, chunk_index, embedding)
VALUES (
  '00000000-0000-0000-0000-000000000001',
  'test.pdf',
  'This is a test chunk about artificial intelligence.',
  0,
  (SELECT array_agg(random())::vector(1536) FROM generate_series(1, 1536))
);

-- Test the search function
SELECT chunk_text, similarity 
FROM match_document_chunks(
  query_embedding := (SELECT embedding::text FROM document_chunks LIMIT 1),
  match_threshold := 0.0,
  match_count := 5
);

-- Clean up
DELETE FROM document_chunks WHERE document_id = '00000000-0000-0000-0000-000000000001';
DELETE FROM rag_documents WHERE id = '00000000-0000-0000-0000-000000000001';
```

**Expected**: Should return the test chunk with similarity score

---

## üîß Troubleshooting

### Error: "extension vector does not exist"

**Solution**: Enable pgvector in Supabase Dashboard:
1. Go to **Database** ‚Üí **Extensions**
2. Search for "vector"
3. Click **Enable**

### Error: "permission denied for schema public"

**Solution**: Run as service_role or check your database permissions

### Error: "column embedding does not exist"

**Solution**: Make sure the `CREATE TABLE` statements ran successfully

### Error: "function match_document_chunks does not exist"

**Solution**: 
1. Check if the function was created: `SELECT * FROM pg_proc WHERE proname = 'match_document_chunks'`
2. Re-run the `CREATE OR REPLACE FUNCTION` part of the migration

---

## üìã Migration Checklist

Before testing RAG Q&A again:

- [ ] Run `01_rag_schema.sql` in Supabase SQL Editor
- [ ] Verify `pgvector` extension is enabled
- [ ] Verify 3 tables exist (`rag_documents`, `document_chunks`, `rag_sessions`)
- [ ] Verify `match_document_chunks` function exists
- [ ] Test vector search with dummy data
- [ ] Try RAG Q&A on your app

---

## ‚úÖ After Running Migration

Once the SQL migration is complete:

1. **Test Q&A with File**:
   - Go to https://frontend-362clzx3p-patricks-projects-1d377b2c.vercel.app
   - Switch to "Ask Questions (RAG)" mode
   - Upload a PDF
   - Process document
   - Ask a question

2. **Test Q&A with URL**:
   - Enter a PDF URL
   - Process URL
   - Ask a question

3. **Expected Flow**:
   ```
   Upload/URL ‚Üí OCR ‚Üí Generate Embeddings ‚Üí Store in document_chunks
                                              ‚Üì
   Ask Question ‚Üí Generate Query Embedding ‚Üí match_document_chunks() ‚Üí Retrieve Chunks ‚Üí LLM Answer
   ```

4. **Verify in Database**:
   ```sql
   -- Check stored chunks
   SELECT COUNT(*) FROM document_chunks;
   
   -- Check Q&A history
   SELECT question, answer FROM rag_sessions ORDER BY created_at DESC LIMIT 5;
   ```

---

## üéØ Why This Happened

### Root Cause

When we initially deployed the RAG Edge Functions, we deployed the **code** (`generate-embeddings`, `rag-query`) but forgot to create the **database schema** (tables, functions, indexes).

The Edge Functions expect:
- ‚úÖ `document_chunks` table to exist
- ‚úÖ `match_document_chunks()` function to exist
- ‚úÖ `pgvector` extension to be enabled

### Lesson Learned

**Always deploy database schema before deploying Edge Functions!**

Proper deployment order:
1. üóÑÔ∏è **Database**: Run SQL migrations
2. üîß **Backend**: Deploy Edge Functions
3. üé® **Frontend**: Deploy UI

---

## üéä Summary

**Problem**: RAG query returning 500 - database schema missing  
**Cause**: Never ran the SQL migration to create tables and RPC function  
**Solution**: Run `01_rag_schema.sql` in Supabase SQL Editor  
**Status**: ‚ö†Ô∏è **ACTION REQUIRED** - You need to run the SQL

**After running the migration, your RAG Q&A will work perfectly!** üéâ

---

## üìö Next Steps

1. ‚úÖ Run the SQL migration (see instructions above)
2. ‚úÖ Test RAG Q&A with a file upload
3. ‚úÖ Test RAG Q&A with a URL
4. ‚úÖ Verify embeddings are being stored in `document_chunks`
5. ‚úÖ Verify Q&A history in `rag_sessions`

---

**Completed by**: AI Assistant  
**Requested by**: Patrick Jaritz  
**Project**: BRAITER Document Intelligence Suite  
**Date**: 2025-01-15

