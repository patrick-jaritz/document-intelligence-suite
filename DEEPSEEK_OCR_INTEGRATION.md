# DeepSeek-OCR Integration Plan

## üìã Overview

**DeepSeek-OCR** is a powerful new OCR model released by DeepSeek AI (October 2025) that reframes OCR as a multimodal LLM task, specifically focused on "Contexts Optical Compression." Unlike traditional OCR engines, it uses a vision-language model approach with n-gram processing for high accuracy.

### Key Features
- üöÄ **State-of-the-art performance** on document OCR tasks
- üìÑ **Markdown conversion** directly from documents
- üéØ **Layout-aware** parsing with grounding capabilities
- üîÑ **Multiple resolution modes** (512√ó512 to 1280√ó1280)
- ‚ö° **Fast inference** with vLLM support (~2500 tokens/s on A100-40G)
- üé® **Support for tables, formulas, and complex layouts**

---

## üîç Comparison with Existing OCR Providers

| Feature | DeepSeek-OCR | PaddleOCR | dots.ocr | OpenAI Vision |
|---------|--------------|-----------|----------|---------------|
| **Model Type** | Vision-Language LLM | Traditional OCR | Layout Parser | Vision Model |
| **Accuracy** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (SOTA) | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Markdown Output** | ‚úÖ Built-in | ‚ùå | ‚úÖ | ‚ùå |
| **Layout Parsing** | ‚úÖ Advanced | ‚ö†Ô∏è Basic | ‚úÖ Advanced | ‚ö†Ô∏è Limited |
| **Hardware** | GPU (CUDA 11.8+) | CPU/GPU | GPU | API |
| **Speed** | ‚ö° Fast (vLLM) | üü° Medium | üü° Medium | üü¢ Very Fast |
| **Cost** | üí∞ Self-hosted | üí∞ Free | üí∞ Free | üí∞ Pay-per-use |
| **Setup Complexity** | üü° Medium | üü¢ Easy | üü° Medium | üü¢ Easy |

---

## üèóÔ∏è Implementation Strategy

### Phase 1: Docker Service Setup (Current)
Create a self-contained Docker service similar to existing PaddleOCR and dots.ocr services.

### Phase 2: API Integration
Integrate with the Supabase Edge Function `process-pdf-ocr` to use DeepSeek-OCR as a provider option.

### Phase 3: Frontend Integration
Add DeepSeek-OCR to the OCR provider selection in the UI.

---

## üì¶ Files to Create

### 1. Service Directory Structure
```
supabase/functions/deepseek-ocr-service/
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ deepseek_ocr_service.py
‚îú‚îÄ‚îÄ run_service.py
‚îî‚îÄ‚îÄ setup.sh
```

### 2. Requirements (`requirements.txt`)
```txt
torch==2.6.0
torchvision==0.21.0
torchaudio==2.6.0
transformers>=4.51.1
vllm>=0.8.5
pillow>=10.0.0
flask>=3.0.0
gunicorn>=21.2.0
pdf2image>=1.16.0
flash-attn==2.7.3
```

### 3. Main Service (`deepseek_ocr_service.py`)
- Flask API endpoint for OCR processing
- Support for both vLLM and Transformers inference
- Image and PDF processing
- Markdown conversion with layout preservation

### 4. Docker Configuration
- CUDA 11.8 base image
- vLLM installation
- Model download on first run
- Health check endpoint

---

## üîß Integration Points

### 1. Update `process-pdf-ocr` Edge Function
Add DeepSeek-OCR as a new OCR provider option:

```typescript
switch (ocrProvider) {
  case 'deepseek-ocr':
    result = await processWithDeepSeekOCR(fileArrayBuffer);
    break;
  // ... existing providers
}
```

### 2. Update OCR Provider Type
```typescript
export type OCRProvider = 
  | 'google-vision'
  | 'ocr-space'
  | 'openai-vision'
  | 'mistral-vision'
  | 'tesseract'
  | 'paddleocr'
  | 'dots-ocr'
  | 'deepseek-ocr'; // NEW
```

### 3. Update Frontend UI
Add "DeepSeek-OCR (SOTA)" option to the OCR provider dropdown in `RAGView.tsx`.

---

## üöÄ Deployment Strategy

### Option 1: Local Development (Recommended for Testing)
1. Run Docker Compose with GPU support
2. Access service at `http://localhost:5003/ocr`
3. Test with sample documents

### Option 2: Cloud Deployment (Railway/Render)
1. Deploy as a separate service with GPU support
2. Update Edge Function to point to cloud URL
3. Add API key authentication for security

### Option 3: Supabase Edge Function (Not Recommended)
- vLLM requires GPU, which Edge Functions don't provide
- Would need to use Transformers CPU inference (very slow)

---

## üìä Expected Benefits

### 1. **Superior Accuracy**
DeepSeek-OCR is state-of-the-art on document OCR benchmarks, potentially outperforming existing providers.

### 2. **Built-in Markdown Conversion**
Direct conversion to structured Markdown, reducing post-processing needs.

### 3. **Layout Preservation**
Advanced layout parsing maintains document structure better than traditional OCR.

### 4. **Multi-language Support**
Built-in support for various languages (English, Chinese, etc.).

### 5. **Cost Efficiency**
Self-hosted solution means no per-page costs after initial setup.

---

## ‚ö†Ô∏è Challenges & Considerations

### 1. **Hardware Requirements**
- Requires GPU (CUDA 11.8+)
- Minimum 16GB VRAM recommended
- A100 or similar for optimal performance

### 2. **Model Size**
- 6.6GB model weights
- First startup will download model (one-time)

### 3. **Startup Time**
- Model loading takes ~1-2 minutes
- Consider warm-up endpoint

### 4. **Cost**
- GPU compute costs if using cloud services
- Local deployment requires GPU hardware

### 5. **Maintenance**
- New model, less battle-tested than PaddleOCR
- Regular updates may be needed

---

## üéØ Recommendation

### For This Project:
**Add DeepSeek-OCR as a premium OCR option** alongside existing providers:

1. **Keep existing providers** (PaddleOCR, dots.ocr, OpenAI Vision) as defaults
2. **Add DeepSeek-OCR** as a "Premium" or "SOTA" option for users with GPU access
3. **Use it for complex documents** where maximum accuracy is required
4. **Offer fallback** to other providers if service is unavailable

### Priority: Medium
- Not critical for MVP
- Great for advanced users
- Best for high-accuracy use cases

---

## üîó Resources

- **Official Repo**: https://github.com/deepseek-ai/DeepSeek-OCR
- **Hugging Face**: https://huggingface.co/deepseek-ai/DeepSeek-OCR
- **Paper**: https://arxiv.org/abs/2510.18234
- **vLLM Integration**: https://docs.vllm.ai/projects/recipes/en/latest/DeepSeek/DeepSeek-OCR.html

---

## üìù Next Steps

1. ‚úÖ Research DeepSeek-OCR capabilities (COMPLETED)
2. ‚è≥ Create Docker service structure
3. ‚è≥ Implement Flask API with vLLM/Transformers
4. ‚è≥ Integrate with Supabase Edge Function
5. ‚è≥ Update frontend UI
6. ‚è≥ Test with sample documents
7. ‚è≥ Deploy and document

---

**Status**: Research phase complete. Ready for implementation if approved.
